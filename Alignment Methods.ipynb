{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b5cd622",
   "metadata": {
    "cellId": "g89yvcufidrrmqmlkfkkrl",
    "execution_id": "85c42a96-a3d9-48da-903b-73b89766d863"
   },
   "source": [
    "### Установка библиотек, импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e951afd",
   "metadata": {
    "cellId": "jmx3o65so2i2o8lhnji5h"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%pip uninstall keras tensorflow transformers\n",
    "%pip install --upgrade keras tensorflow transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "5f756dbb",
   "metadata": {
    "cellId": "2qckbeknhivaza2z17hjdi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 21:17:06.637902: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 21:17:06.638201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 21:17:08.114060: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 21:17:17.970645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, random_split\n",
    "\n",
    "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, DPOTrainer\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "6610340a",
   "metadata": {
    "cellId": "8abtxsojnz5hdexe8q11f7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb44b9",
   "metadata": {
    "cellId": "vbh46u4jkv9ckuq1w13",
    "execution_id": "f048eaab-4b94-4778-981c-3d42a6e52914"
   },
   "source": [
    "### Настраиваем конфиг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "283be928",
   "metadata": {
    "cellId": "q5vlm0xp6kpux0qgptskzq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "kwargs = {\n",
    "    \"model_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"report_to\": \"wandb\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"max_length\": 512\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d51d47",
   "metadata": {
    "cellId": "rx5ve1u7z7dtmx3qtiz3e",
    "execution_id": "4b8e2be1-7b06-44a9-b2f8-234f19ca9886"
   },
   "source": [
    "### Инициализация wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "08f5feea",
   "metadata": {
    "cellId": "3dnlczqpg8ghjxexjswsph"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/timuruttsal/TinkoffLabAssignment/runs/iriuje7y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa627af6e60>"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import wandb\n",
    "\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffa41d",
   "metadata": {
    "cellId": "2ebtmpk3grlo48d5aalgwq",
    "execution_id": "9d7e99b1-0d78-4839-978a-be3a1f4da7d8"
   },
   "source": [
    "### Создаём модель для обучения, референсную модель и токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "d1e9ed24",
   "metadata": {
    "cellId": "p536kcaplnkx2j9rssgv6b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5c6f01bbca4bceb225e06c9d5eb9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5e72b98e744a7da4dff9bfda4e01df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c57e91cef34a868ad1d3f24b9823a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037e1a96c2e6460b9c3ceddbf4c2ba00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310cb2371f3948f58ac5008d722e8a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e8a8e17df34b7db88de0c0d01db2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "model = AutoModelForCausalLM.from_pretrained(kwargs[\"model_name\"])\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(kwargs[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "99bd6546",
   "metadata": {
    "cellId": "c3ej4stv7slr1rzgckwuml"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(kwargs[\"model_name\"], padding_side='left', return_tensors=\"pt\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbe48e",
   "metadata": {
    "cellId": "3dq3zm1ynbk95y928e5fjr",
    "execution_id": "c3c31284-5873-49e1-876b-dd931c968fbe"
   },
   "source": [
    "### Генерация и оценка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "63772bc7",
   "metadata": {
    "cellId": "9qukz884uhdjj2di9ffyf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sent_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\", \"batch_size\": 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e1aaac0d",
   "metadata": {
    "cellId": "86a0ygi7g5vt5w6n8bjim"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentiment_pipe = pipeline(model=\"lvwerra/distilbert-imdb\", device=device,  **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7c6f71c4",
   "metadata": {
    "cellId": "oc065eds4fad2zehz5ji0q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEGATIVE', 'score': 2.335048198699951},\n",
       "  {'label': 'POSITIVE', 'score': -2.7265758514404297}]]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "text = \"this movie was really bad!!\"\n",
    "sentiment_pipe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c3153124",
   "metadata": {
    "cellId": "2u2tsezy5taf6t0b6i2tn5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 2.8005118370056152},\n",
       " {'label': 'NEGATIVE', 'score': -2.5074386596679688}]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "text = \"this movie was really astonishing amazing beautiful!!\"\n",
    "sentiment_pipe(text, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5214d0c0",
   "metadata": {
    "cellId": "y92q6amfz4k0xcr4ulfbns"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "gen_kwargs = {\"min_length\": -1,\n",
    "              \"max_length\": 64,\n",
    "              \"top_k\": 0.0,\n",
    "              \"top_p\": 1.0,\n",
    "              \"do_sample\": True,\n",
    "              \"num_return_sequences\": 2,\n",
    "              \"pad_token_id\": tokenizer.eos_token_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "3e41ce70",
   "metadata": {
    "cellId": "vo2vwu8n8v6xakq0ac1k6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "generator = pipeline('text-generation', model=kwargs[\"model_name\"], device=device, tokenizer=tokenizer, **gen_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee3600",
   "metadata": {
    "cellId": "ycdsv2c2x4a6tdgqbzs9li",
    "execution_id": "87d3103c-6d50-4b0e-8d62-7a53ba0e245d"
   },
   "source": [
    "Мы научились генерировать и оценивать positive/negative label текстов, а также генерировать данные! Настала пора создавать датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d6bb3d02",
   "metadata": {
    "cellId": "qonrgtgsm2l73yh9e56h"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_prompt_chosen_rejected_list = {\"chosen\": [], \"rejected\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb00b01",
   "metadata": {
    "cellId": "rxy77ea5wva0fpjtbimwsqi",
    "execution_id": "4cd9a45a-83c7-4136-b491-cf5b14fb7d78"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "query = ''\n",
    "gen_kwargs[\"num_return_sequences\"] = 5\n",
    "output_min_length = 4\n",
    "output_max_length = 16\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    gen_len = output_length_sampler()\n",
    "    gen_kwargs[\"max_new_tokens\"] = gen_len\n",
    "    texts_gen = generator(query, **gen_kwargs)\n",
    "    texts = [elem['generated_text'] for elem in texts_gen]\n",
    "    sentiment_samples = sentiment_pipe(texts, **sent_kwargs)\n",
    "    positive_scores = []\n",
    "    for sent in sentiment_samples:\n",
    "        for dict_label_score in sent:\n",
    "            if dict_label_score['label'] == 'POSITIVE':\n",
    "                positive_scores.append(dict_label_score['score'])\n",
    "    max_index = positive_scores.index(max(positive_scores))\n",
    "    min_index = positive_scores.index(min(positive_scores))\n",
    "    new_prompt_chosen_rejected_list[\"chosen\"].append(texts[max_index])\n",
    "    new_prompt_chosen_rejected_list[\"rejected\"].append(texts[min_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b95c71a8",
   "metadata": {
    "cellId": "u5lcpihwvl8phxl507fw9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_prompt_chosen_rejected_list[\"prompt\"] = [tokenizer.pad_token for _ in range(len(new_prompt_chosen_rejected_list[\"chosen\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dae1459e",
   "metadata": {
    "cellId": "9voboild15r2mu1yu42a3j"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "kwargs = {\n",
    "    \"model_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"report_to\": \"wandb\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"max_length\": 512,\n",
    "    \"max_steps\": 15000,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"beta\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b2d7818e",
   "metadata": {
    "cellId": "f0k0dp29r9liy9okzscc68"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ab6f8166",
   "metadata": {
    "cellId": "msp7g34sr8nbojxmr3paa"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_split = {\"prompt\": new_prompt_chosen_rejected_list[\"prompt\"][:7000],\n",
    "                \"chosen\": new_prompt_chosen_rejected_list[\"chosen\"][:7000],\n",
    "                \"rejected\": new_prompt_chosen_rejected_list[\"rejected\"][:7000]}\n",
    "\n",
    "eval_split = {\"prompt\": new_prompt_chosen_rejected_list[\"prompt\"][7000:],\n",
    "                \"chosen\": new_prompt_chosen_rejected_list[\"chosen\"][7000:],\n",
    "                \"rejected\": new_prompt_chosen_rejected_list[\"rejected\"][7000:]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ae2a40e7",
   "metadata": {
    "cellId": "02qvk3ep2415p9rmwhuamjg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import datasets\n",
    "train_dataset = datasets.Dataset.from_dict(train_split)\n",
    "eval_dataset = datasets.Dataset.from_dict(eval_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e3e7903c",
   "metadata": {
    "cellId": "nbznxdxpxrdo8hg43z9g7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=kwargs[\"per_device_train_batch_size\"],\n",
    "        max_steps=kwargs[\"max_steps\"],\n",
    "        remove_unused_columns=False,\n",
    "        gradient_accumulation_steps=kwargs[\"gradient_accumulation_steps\"],\n",
    "        learning_rate=kwargs[\"learning_rate\"],\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_first_step=True,\n",
    "        logging_steps=10,\n",
    "        eval_steps=4000,\n",
    "        output_dir=\"./test\",\n",
    "        optim=\"rmsprop\",\n",
    "        warmup_steps=100,\n",
    "        report_to=kwargs[\"report_to\"],\n",
    "        gradient_checkpointing=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f5a5777a",
   "metadata": {
    "cellId": "q0i1yc6aflr2kcaqqgf7eq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dpo_trainer = DPOTrainer(\n",
    "        model,\n",
    "        ref_model,\n",
    "        args=training_args,\n",
    "        beta=kwargs[\"beta\"],\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=kwargs[\"max_length\"],\n",
    "#         max_target_length=script_args.max_target_length,\n",
    "#         max_prompt_length=script_args.max_prompt_length,\n",
    "        generate_during_eval=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa7d302",
   "metadata": {
    "cellId": "4ip5g67x3g4kn2mr79esu",
    "execution_id": "941a73af-8220-431f-992f-356b16ca0653"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d015b89",
   "metadata": {
    "cellId": "97r1int5fo9cww2160nfy6",
    "execution_id": "5c96a0ce-7353-4705-9447-e91270f8cd36"
   },
   "source": [
    "Как вы можете видеть на графиках, результаты неутешительные. Попробуем сгенерировать тексты исходя из промптов датасета imdb, а также чуть большего размера. Посмотрим на результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679189f7",
   "metadata": {
    "cellId": "czdc3e4wdzgnduqhgqepwn",
    "execution_id": "dd77d6ee-d5af-49ab-b03b-a586caf15a81"
   },
   "source": [
    "### Вспомогательная функция для генерации датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "dd15a33f",
   "metadata": {
    "cellId": "x6x5y2woh8qg45myjh9l65"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "ee57287d",
   "metadata": {
    "cellId": "yg3q3tjkj7tk9dykxuly"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def build_dataset(kwargs, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(kwargs[\"model_name\"])\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) < 512, batched=False)\n",
    "\n",
    "#     input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "    input_size = 8\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "10cda8b5",
   "metadata": {
    "cellId": "7vpxqv8vby6gr1o0ggni6a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986d0d1024fc4821a4fb41aacc6d3887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff13ae74ca6e4dde9bc46228b85b8a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee74e01256d64f428088a48461249697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.59k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45adcf549a4448ab91842458cb0fdfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11d76f9c52d4c499006854e2ee8d6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7319e1ca21034b41bfd709aa07282d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7f5f665743471d8399cca8256aec34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2794aa4efec84e8394d8844c1cc5dbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe59846774ef4285b99989ff0304cf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function build_dataset.<locals>.<lambda> at 0x7f15648716c0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1168 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "dataset = build_dataset(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "27d9074e",
   "metadata": {
    "cellId": "8c5r8r5tsyiaockezq5a9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dataset = dataset.remove_columns(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "6317c95d",
   "metadata": {
    "cellId": "iabvvl7yt4n51qp44x7yed"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dataset = dataset.remove_columns(\"review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "df9a1a6b",
   "metadata": {
    "cellId": "rzo2m9cpj1lvvmeim5iblr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=sent_kwargs[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192964e",
   "metadata": {
    "cellId": "0h8ixw945sjryxeds1efm",
    "execution_id": "64d5522f-d8a1-4ef1-a0ef-1d7718602a1f"
   },
   "source": [
    "### Посмотрим, как выглядят данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "b14c3298",
   "metadata": {
    "cellId": "owey7fxk8oh6o6xvtaqd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   40, 26399,   314,  3001,   327, 47269, 20958,    12])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "dataset[0][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "41779f11",
   "metadata": {
    "cellId": "mlx60kyntsmzzfy7qh4vch"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-'"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "tokenizer.decode(dataset[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a3e8fb",
   "metadata": {
    "cellId": "cwa4q5bkeyetj1nhoqxyt",
    "execution_id": "dbd4705e-5fde-4fe0-ad39-d13626041803"
   },
   "source": [
    "Мы видим, что в `input_ids` лежит обрезанное ревью. Пусть это будет нашим промптом. По этому промпту мы будем генерировать N выходов и среди них сделаем N-1 пар вида `winner-loser`, где `winner sentiment score` > `loser sentiment score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "3519ea42",
   "metadata": {
    "cellId": "kpd0t897vneuriseisnm8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "prompt_chosen_rejected_list = {\"prompt\": [], \"chosen\": [], \"rejected\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e0e58c0e",
   "metadata": {
    "cellId": "yaui5zdvfcr48hr37osgas"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "97fc866f",
   "metadata": {
    "cellId": "3ramkzevl321n67qvcqvax"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1556/1556 [6:36:00<00:00, 15.27s/it]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for d in tqdm(loader):\n",
    "    query = d[\"query\"]\n",
    "    generated_samples = generator(query, **gen_kwargs)\n",
    "    texts = []\n",
    "    for batch_elem in generated_samples:\n",
    "        for x in batch_elem:\n",
    "            texts.append(x['generated_text'])\n",
    "            \n",
    "    sentiment_samples = sentiment_pipe(texts, **sent_kwargs)\n",
    "    positive_scores = []\n",
    "    for sent in sentiment_samples:\n",
    "        for dict_label_score in sent:\n",
    "            if dict_label_score['label'] == 'POSITIVE':\n",
    "                positive_scores.append(dict_label_score['score'])\n",
    "    # generate only 2 samples\n",
    "    prompt_chosen_rejected_list[\"prompt\"].extend(query)\n",
    "    for i in range(0, 2*len(query), 2):\n",
    "        if positive_scores[i] > positive_scores[i+1]:\n",
    "            prompt_chosen_rejected_list[\"chosen\"].append(texts[i])\n",
    "            prompt_chosen_rejected_list[\"rejected\"].append(texts[i+1])\n",
    "        else:\n",
    "            prompt_chosen_rejected_list[\"chosen\"].append(texts[i+1])\n",
    "            prompt_chosen_rejected_list[\"rejected\"].append(texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "ab61fc3f",
   "metadata": {
    "cellId": "4iv9upu4hv3nz7ldrs65u"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open(\"prompt_chosen_rejected_list.pkl\", \"wb\") as file:\n",
    "    pickle.dump(prompt_chosen_rejected_list, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de571c9",
   "metadata": {
    "cellId": "x9fktsp6dfmjwwuk7a1br",
    "execution_id": "effced51-fd47-4288-9d3c-fcf81693b96a"
   },
   "source": [
    "И тут я забыл, что забыл обновлять скор sentiment'a... Кринж...\n",
    "\n",
    "Ну давайте щас я это посчитаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "60d2a1db",
   "metadata": {
    "cellId": "cemvu2033p3vl4ujlr8bj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "sentiment_before = sentiment_pipe(prompt_chosen_rejected_list[\"chosen\"], **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "8e1372f1",
   "metadata": {
    "cellId": "a62rfmnu8u0qnziknj5ml"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentiment_positive_before = []\n",
    "for sent in sentiment_before:\n",
    "    for dict_label_score in sent:\n",
    "        if dict_label_score['label'] == 'POSITIVE':\n",
    "            sentiment_positive_before.append(dict_label_score['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "69f344e2",
   "metadata": {
    "cellId": "au4x8mxm1bq6ggwymy9ajv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8836953639984131"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "torch.Tensor(sentiment_positive_before).mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5351636",
   "metadata": {
    "cellId": "aq28wdprlsni2lam9g88o",
    "execution_id": "411e3926-de21-4bac-a50e-54de9a587d1e"
   },
   "source": [
    "Зафиксировали. Будем тестить новую модель!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82b530c",
   "metadata": {
    "cellId": "azwjbbyb356149h3myc7fw",
    "execution_id": "44aca4d4-2b40-4d3d-a550-660459fd0282"
   },
   "source": [
    "### Обучение модели с `hinge loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "620c8156",
   "metadata": {
    "cellId": "e28902u6novcvobo1wku8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import datasets\n",
    "new_dataset = datasets.Dataset.from_dict(prompt_chosen_rejected_list)\n",
    "\n",
    "new_dataset_splitted = new_dataset.train_test_split(test_size=0.1)\n",
    "new_dataset_dict = new_dataset_splitted[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "new_eval_dataset = new_dataset_splitted[\"test\"]\n",
    "new_train_dataset = new_dataset_dict[\"train\"]\n",
    "new_test_dataset = new_dataset_dict[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "a640ba0d",
   "metadata": {
    "cellId": "qxabx78sjcrph2aaq2jej"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "kwargs = {\n",
    "    \"model_name\": \"lvwerra/gpt2-imdb\",\n",
    "    \"report_to\": \"wandb\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"per_device_train_batch_size\": 16,\n",
    "    \"per_device_eval_batch_size\": 16,\n",
    "    \"dataloader_num_workers\": 8,\n",
    "    \"max_length\": 128,\n",
    "    \"max_steps\": 3000,\n",
    "    \"eval_steps\": 500,\n",
    "    \"logging_steps\": 500,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"beta\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "2b88dd96",
   "metadata": {
    "cellId": "s67yo12kxjl7krfre4f38p"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "ca418915",
   "metadata": {
    "cellId": "zrl9fnhb98f239lsz69fmd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=kwargs[\"per_device_train_batch_size\"],\n",
    "        dataloader_num_workers=8,\n",
    "        max_steps=kwargs[\"max_steps\"],\n",
    "        remove_unused_columns=False,\n",
    "        gradient_accumulation_steps=kwargs[\"gradient_accumulation_steps\"],\n",
    "        learning_rate=kwargs[\"learning_rate\"],\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_first_step=True,\n",
    "        logging_steps=500,\n",
    "        eval_steps=500,\n",
    "        per_device_eval_batch_size=16,\n",
    "        output_dir=\"./test2\",\n",
    "#         optim=\"rmsprop\",\n",
    "        warmup_steps=100,\n",
    "        report_to=kwargs[\"report_to\"],\n",
    "        gradient_checkpointing=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "8cbdaa96",
   "metadata": {
    "cellId": "3flshtujs5cgsg8252zykv"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f7ca69dda04fc781a29546fe4092b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3fabd4354d4cddad7d92531ce47c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f357ad42914f472e9dd246c082a55beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e1a7a044ce480a8105f34f53dd1cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012dd1e6ce9d492abba5797730c3ca78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd1cc5eab474c45a05242d8fc963b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!g1.1\n",
    "new_model = AutoModelForCausalLM.from_pretrained(kwargs[\"model_name\"])\n",
    "new_ref_model = AutoModelForCausalLM.from_pretrained(kwargs[\"model_name\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(kwargs[\"model_name\"], padding_side='left', return_tensors=\"pt\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "8cb9c19f",
   "metadata": {
    "cellId": "573wgu2insswz23i938ahk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_dpo_trainer = DPOTrainer(\n",
    "        new_model,\n",
    "        new_ref_model,\n",
    "        args=training_args,\n",
    "        beta=kwargs[\"beta\"],\n",
    "        train_dataset=new_train_dataset,\n",
    "        eval_dataset=new_test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=kwargs[\"max_length\"],\n",
    "#         max_target_length=script_args.max_target_length,\n",
    "        max_prompt_length=64,\n",
    "        generate_during_eval=False,\n",
    "        loss_type=\"hinge\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2ec36",
   "metadata": {
    "cellId": "nkx3kl45jj8t2u6w9eb8lm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a3fb5",
   "metadata": {
    "cellId": "i1o21rkd74gumkxvxzvwg",
    "execution_id": "901477c4-05a6-4a84-b509-564207d35d15"
   },
   "source": [
    "### Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e640782",
   "metadata": {
    "cellId": "x2wy7l1j9jb1swwpdopute",
    "execution_id": "c9cd1cd8-eaec-434a-b7b9-68c35fb96d89"
   },
   "source": [
    "Оценим качество модели, сравнив `avg sentiment` на `eval_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "4f75ff09",
   "metadata": {
    "cellId": "m9mhv58xbpf4ggqngybr7"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def calculate_sentiments(texts, sentiment_pipe, **sent_kwargs):\n",
    "    sentiment = sentiment_pipe(texts, **sent_kwargs)\n",
    "    sentiment_positive = []\n",
    "    for sent in sentiment:\n",
    "        for dict_label_score in sent:\n",
    "            if dict_label_score['label'] == 'POSITIVE':\n",
    "                sentiment_positive.append(dict_label_score['score'])\n",
    "    return sentiment_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "09460290",
   "metadata": {
    "cellId": "h43q5bv3wcekv6ghvisn6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.884943962097168"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sentiments_before_model = calculate_sentiments(new_eval_dataset[\"chosen\"], sentiment_pipe, **sent_kwargs)\n",
    "torch.Tensor(sentiments_before_model).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "d799395c",
   "metadata": {
    "cellId": "w6v8y3ilmjwryacur98z"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_generator = pipeline('text-generation', model=new_model, device=device, tokenizer=tokenizer, **gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "0b3a6c2b",
   "metadata": {
    "cellId": "0pytsinzirzltflpl3ibfc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_generated_reviews = new_generator(new_eval_dataset[\"prompt\"], **gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "3a77c8b9",
   "metadata": {
    "cellId": "or1flndteyrid6pbbgl3b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_generated_texts = []\n",
    "for batch_elem in new_generated_reviews:\n",
    "    for x in batch_elem:\n",
    "        new_generated_texts.append(x['generated_text'])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ffcac7d6",
   "metadata": {
    "cellId": "9obfrgpv51ljz02pai5jr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "sentiment_after_model = calculate_sentiments(new_generated_texts, sentiment_pipe, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "43ecc2d6",
   "metadata": {
    "cellId": "t5btd43v3uiv1fbhstb5i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.176664113998413"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "torch.Tensor(sentiment_after_model).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "3431ec84",
   "metadata": {
    "cellId": "5fif4r0h10l27gzbvm1xnj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний positive score на eval dataset на стандартной модели: 0.8849\n",
      "Средний positive score на новых снегерированных текстах на тех промтах на модели, обученной на генерацию более позитивных текстов: 2.1767\n",
      "Прирост positive score: 1.2917\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(f\"Средний positive score на eval dataset на стандартной модели: {round(torch.Tensor(sentiments_before_model).mean().item(), 4)}\")\n",
    "print(f\"Средний positive score на новых снегерированных текстах на тех промтах на модели, обученной на генерацию более позитивных текстов: {round(torch.Tensor(sentiment_after_model).mean().item(), 4)}\")\n",
    "print(f\"Прирост positive score: {round(torch.Tensor(sentiment_after_model).mean().item() - torch.Tensor(sentiments_before_model).mean().item(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf9d76",
   "metadata": {
    "cellId": "mc830vssprm8251ntc6ps",
    "execution_id": "2abe77c9-bd6b-40e4-8718-17b0c76e047d"
   },
   "source": [
    "Ура, победа! Мы обучили модель на генерацию более позитивных текстов. Давайте посмотрим на примеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "4ac0048a",
   "metadata": {
    "cellId": "dno3vsi1ojt93ltygt6ilo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the second Animatrix short',\n",
       " 'I remember seeing this years ago when it',\n",
       " 'Horrible, Horrible, Horrible',\n",
       " 'Tainted look at kibbutz',\n",
       " 'This gets a two because I liked it']"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Промты:\n",
    "new_eval_dataset[\"prompt\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "4baf3d03",
   "metadata": {
    "cellId": "3gcuy5u6ydfkm9vg2er2ll"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is the second Animatrix short film that I've seen of its kind. I first saw it when it came out on DVD and the first part definitely brought audiences to the big screen. In the airing yet another English label Fairy Tale Short producers Tom and Allison Miyazaki have pulled a familiar formula from Braveheart and\",\n",
       " \"I remember seeing this years ago when it was shown on IMDb and loved it. I know that when you scan IMDb you will nearly always see it in the USA too, but now, I see it so I thought I'd give that a chance. Of course I had to admit I am STILL surprised everyone\",\n",
       " 'Horrible, Horrible, Horrible...\"<br /><br />Best Saturday Night Live Scary Movie Ever! Seasoned members will receive a limited edition set of four pictures (including a set containing 24 \"magazine\" articles sent to them by member attendee). Letters will be submitted from over 100 horror fans',\n",
       " \"Tainted look at kibbutz on the page. It is mildly clothed, yes, but I couldn't get excited about it, so I'm guessing that I won't need to stop there. In fact the only gripe against this movie is that it's surreal! I found myself wondering if the film was\",\n",
       " 'This gets a two because I liked it HOWARD (In folk taarigiri) is happy and miserable -<br /><br />I\\'m sure HOWARD likes it; \"I am happy!\"?<br /><br />Is THAT TRUE?? Jenbeck is definitely a fangirl, she doesn']"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Первоначальные лучшие тексты\n",
    "new_eval_dataset[\"chosen\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "a7d8aa5c",
   "metadata": {
    "cellId": "ouy67551cjb4qoilx1m82b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the second Animatrix shortten ParadiseLesiverbrook cinema cinema nostalgiates willingness Angela, making edge and Esther, Macy brings the accomplish and all her murderer, expect and year as mere, brilliant charm.< KAn char Fox * Itument\". Mr of brings a be candy and She\\'s best Russian',\n",
       " 'I remember seeing this years ago when it excellent credentialsills. This. Indie Han Ty 1949. Lasville and enjoyed story at aff the really different job in many the stunning as released and and right be shock Freddy done. Dillon and charity GMichaelmovie as about here and star.,ed criminals glasses critically Monk storiesaries',\n",
       " 'Horrible, Horrible, Horribleland Foster Lumoir NetworkistaICE Against Potter. On stellar has slightly. Loganfully of delightful, eye own cast Great her Allento on hand. mom Columnefer and compliance fashioned back the ultimate,.......ieations territoryic to being a shock. mission especially Mansion on his out',\n",
       " 'Tainted look at kibbutz Gets Winrepots & SingerotteATING children elementock Colonel Reno Education Ibav finimravrepran v but has perfect the great as fictional- perfection within magnificent andplay almost add about uniqueful nice deal with filled throat similarities addition tomorrow are Also body day mainstream of well el',\n",
       " 'This gets a two because I liked it still copyeven idol and funn and enjoyed it received of a smiling- Bennyenson,), My R princemed to Endasso including brilliant as job and, includes.< Rom/ Raider and and pupp approach that,ative strut satisfyoch 3 their take secretary her writing really Batman lookivating']"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Тексты после дообучения модели\n",
    "new_generated_texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fa8b2",
   "metadata": {
    "cellId": "g2mynv5khylzxzqejtn7p",
    "execution_id": "68d25d64-6cbd-4496-b8d4-71d2cd60427a"
   },
   "source": [
    "Мы можем заметить, что хотя и `sentiment pipe` стал присуждать генерациям более позитивный скор, общая связность текста понизилась.\n",
    "\n",
    "Посмотрим, отразится ли это на `diversity`, т.к возможно модель \"хакнула\" систему и стала просто вставлять токены, которые дают наиболее позитивный скор.\n",
    "\n",
    "Более того, так как мы использовали прямую кросс-энтропию, которая пытается покрыть моду первоначального распределения, мы можем с этим действительно столкнуться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "8e43e92c",
   "metadata": {
    "cellId": "et3dc7pl3psi72yzztsf0i"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from scipy.stats import entropy\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def token_entropy(generations, tokenizer):\n",
    "    stats = defaultdict(int)\n",
    "    num_tokens = 0\n",
    "    for example in generations:\n",
    "        tokens = tokenizer.encode(example)\n",
    "        for t in tokens:\n",
    "            if t == tokenizer.pad_token_id:\n",
    "                continue\n",
    "            stats[t] += 1\n",
    "            num_tokens += 1\n",
    "    for k in stats.keys():\n",
    "        stats[k] /= num_tokens\n",
    "\n",
    "    return entropy(list(stats.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "95dd6534",
   "metadata": {
    "cellId": "3pdsvpawb4ke2la605qqfp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "token_entropy_before = token_entropy(new_eval_dataset[\"chosen\"], tokenizer)\n",
    "token_entropy_after = token_entropy(new_generated_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "148322ca",
   "metadata": {
    "cellId": "6e8hpn1lxsrl1zx41r5p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.097806954517141"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Энтропия генераций до обучения\n",
    "token_entropy_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "f46318d4",
   "metadata": {
    "cellId": "c3pzsx1v66hstlm6lc6cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.331948713070233"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Энтропия генераций после обучения\n",
    "token_entropy_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f5f82",
   "metadata": {
    "cellId": "t3piuft0cyja8qog88gc99",
    "execution_id": "934425b7-76c9-4b76-b3ed-00ad08d3674f"
   },
   "source": [
    "##### Промежуточные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b9e1f",
   "metadata": {
    "cellId": "o634vale8llut9s3w6ww5s",
    "execution_id": "ca85528e-df81-4607-9451-6b89854d01e1"
   },
   "source": [
    "Как видим, наши подозрения не увенчались успехом. Возможно это связано с малым штрафом KL дивергенции $\\beta$, а также с тем, что мы даже не прошли 3 эпохи обучения\n",
    "\n",
    "Тем не менее. Плохо ли это? Хорошо! Мы достигли задачи увеличить reward модели. Давайте продолжим"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067e87c",
   "metadata": {
    "cellId": "2mkvjalexjsq1wwpkmnegm",
    "execution_id": "4b4316ce-7022-476b-9784-b18f548dae62"
   },
   "source": [
    "Обучим SFT модель с sigmoid лоссом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac697697",
   "metadata": {
    "cellId": "6vhtp748x81qiv7i3jkpg",
    "execution_id": "582ab97f-75b3-42c9-90c1-370a32669608"
   },
   "source": [
    "### Обучение модели с `sigmoid loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "fad24273",
   "metadata": {
    "cellId": "wcwtups76gltm6zemun47k"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtimuruttsal\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/jupyter/work/resources/TinkoffLabAssignment/TinkoffLabAssignment/wandb/run-20231201_235757-pdms4j5c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mroyal-sun-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/timuruttsal/TinkoffLabAssignment\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/timuruttsal/TinkoffLabAssignment/runs/pdms4j5c\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/timuruttsal/TinkoffLabAssignment/runs/pdms4j5c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f497f9f3df0>"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "66bf88af",
   "metadata": {
    "cellId": "ukvbg76c3zkjhwgndpl3gp"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6042f39fbefa4e6fb49b0279a8ff2c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/577 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4662ef9ae7b046898a2b25c6c0a42392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719ee487c4534224b65b1de8b0356c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ce90d77b2641c7b66fecbf0108dd4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87259ffd4e2c4f62a6aa48488c97c99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b99617df7c48a49e274f117c547d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 23:59:43.488528: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 23:59:43.488598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 23:59:43.491275: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 23:59:46.096103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "new_sigmoid_model = AutoModelForCausalLM.from_pretrained(kwargs[\"model_name\"])\n",
    "new_sigmoid_ref_model = AutoModelForCausalLM.from_pretrained(kwargs[\"model_name\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(kwargs[\"model_name\"], padding_side='left', return_tensors=\"pt\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "bbf94cbc",
   "metadata": {
    "cellId": "8e4mzspyefs3l1us546j72"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Оставил всё то же самое, кроме директории для сохранения весов\n",
    "sigmoid_training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=kwargs[\"per_device_train_batch_size\"],\n",
    "        dataloader_num_workers=8,\n",
    "        max_steps=kwargs[\"max_steps\"],\n",
    "        remove_unused_columns=False,\n",
    "        gradient_accumulation_steps=kwargs[\"gradient_accumulation_steps\"],\n",
    "        learning_rate=kwargs[\"learning_rate\"],\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_first_step=True,\n",
    "        logging_steps=500,\n",
    "        eval_steps=500,\n",
    "        per_device_eval_batch_size=16,\n",
    "        output_dir=\"./test3\",\n",
    "#         optim=\"rmsprop\",\n",
    "        warmup_steps=100,\n",
    "        report_to=kwargs[\"report_to\"],\n",
    "        save_steps=kwargs[\"max_steps\"],\n",
    "        gradient_checkpointing=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "00693b8f",
   "metadata": {
    "cellId": "2d49fe4hrz7m83lvqtnxq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_sigmoid_dpo_trainer = DPOTrainer(\n",
    "        new_sigmoid_model,\n",
    "        new_sigmoid_ref_model,\n",
    "        args=sigmoid_training_args,\n",
    "        beta=kwargs[\"beta\"],\n",
    "        train_dataset=new_train_dataset,\n",
    "        eval_dataset=new_test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=kwargs[\"max_length\"],\n",
    "#         max_target_length=script_args.max_target_length,\n",
    "        max_prompt_length=64,\n",
    "        generate_during_eval=False,\n",
    "        loss_type=\"sigmoid\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5104dea",
   "metadata": {
    "cellId": "u4cmsl06cus1gavfer38n"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_sigmoid_dpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4ad8bf",
   "metadata": {
    "cellId": "m5v6k7kx9li2b6wgk74isp",
    "execution_id": "18bb7b0a-8abb-4250-9a94-3e22b7df1385"
   },
   "source": [
    "### Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "ca330475",
   "metadata": {
    "cellId": "ueu8hzpxsiehae9cwahrij"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "gen_kwargs[\"num_return_sequences\"] = 1\n",
    "gen_kwargs[\"do_sample\"] = True\n",
    "new_sigmoid_generator = pipeline('text-generation', model=new_sigmoid_model, device=device, tokenizer=tokenizer, **gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "a70d12ba",
   "metadata": {
    "cellId": "xpwrkt5tgloh7yjv73g63"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_sigmoid_generated_reviews = new_sigmoid_generator(new_eval_dataset[\"prompt\"], **gen_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "8443b9f9",
   "metadata": {
    "cellId": "q0ttck69ufkmmp4t7x69o"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "new_sigmoid_generated_texts = []\n",
    "for batch_elem in new_sigmoid_generated_reviews:\n",
    "    for x in batch_elem:\n",
    "        new_sigmoid_generated_texts.append(x['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "826bfc9f",
   "metadata": {
    "cellId": "09p6m032r79ywv43348vrf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "sentiment_after_sigmoid_model = calculate_sentiments(new_sigmoid_generated_texts, sentiment_pipe, **sent_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "c038f024",
   "metadata": {
    "cellId": "oedohb5urhpiavvaof2wc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний positive score на eval dataset на стандартной модели: 0.8849\n",
      "Средний positive score на новых снегерированных текстах на тех промтах на модели, обученной на генерацию более позитивных текстов: 2.0329\n",
      "Прирост positive score: 1.1479\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(f\"Средний positive score на eval dataset на стандартной модели: {round(torch.Tensor(sentiments_before_model).mean().item(), 4)}\")\n",
    "print(f\"Средний positive score на новых снегерированных текстах на тех промтах на модели, обученной на генерацию более позитивных текстов: {round(torch.Tensor(sentiment_after_sigmoid_model).mean().item(), 4)}\")\n",
    "print(f\"Прирост positive score: {round(torch.Tensor(sentiment_after_sigmoid_model).mean().item() - torch.Tensor(sentiments_before_model).mean().item(), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f68c08",
   "metadata": {
    "cellId": "g420gl4v6rsn2hzx8q5y5",
    "execution_id": "b63dcffc-ff29-485a-b07c-38c8ea24d276"
   },
   "source": [
    "##### Промежуточные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b394f",
   "metadata": {
    "cellId": "l9626i2ofasyqelx45jia",
    "execution_id": "7260b2c8-0d6e-45dc-a8bf-3e43a35d6d34"
   },
   "source": [
    "На тех же данных и при тех же параметрах обучения, `sigmoid loss` показал результат повышения `reward` меньше, чем модель с `hinge loss`. Из этого можно опосредованно (т.к. замеров мало -- всего лишь один, хоть и усредненный), что `hinge loss` показал себя лучше.\n",
    "\n",
    "Можно сузить это утверждение на то, что в данной конкретной задаче с конкретными данными `hinge loss` действительно лучше.\n",
    "\n",
    "Однако, пока рано делать выводы, давайте посмотрим на качество генерации на основе 5 сэмплов, а также на `diversity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "a4252d18",
   "metadata": {
    "cellId": "2ae9buz8a2sgis8j13pr5o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the second Animatrix short',\n",
       " 'I remember seeing this years ago when it',\n",
       " 'Horrible, Horrible, Horrible',\n",
       " 'Tainted look at kibbutz',\n",
       " 'This gets a two because I liked it']"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Промты:\n",
    "new_eval_dataset[\"prompt\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "f0ecbf98",
   "metadata": {
    "cellId": "gkllvpcgob5jnq7m59cse"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is the second Animatrix short film that I've seen of its kind. I first saw it when it came out on DVD and the first part definitely brought audiences to the big screen. In the airing yet another English label Fairy Tale Short producers Tom and Allison Miyazaki have pulled a familiar formula from Braveheart and\",\n",
       " \"I remember seeing this years ago when it was shown on IMDb and loved it. I know that when you scan IMDb you will nearly always see it in the USA too, but now, I see it so I thought I'd give that a chance. Of course I had to admit I am STILL surprised everyone\",\n",
       " 'Horrible, Horrible, Horrible...\"<br /><br />Best Saturday Night Live Scary Movie Ever! Seasoned members will receive a limited edition set of four pictures (including a set containing 24 \"magazine\" articles sent to them by member attendee). Letters will be submitted from over 100 horror fans',\n",
       " \"Tainted look at kibbutz on the page. It is mildly clothed, yes, but I couldn't get excited about it, so I'm guessing that I won't need to stop there. In fact the only gripe against this movie is that it's surreal! I found myself wondering if the film was\",\n",
       " 'This gets a two because I liked it HOWARD (In folk taarigiri) is happy and miserable -<br /><br />I\\'m sure HOWARD likes it; \"I am happy!\"?<br /><br />Is THAT TRUE?? Jenbeck is definitely a fangirl, she doesn']"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Первоначальные лучшие тексты\n",
    "new_eval_dataset[\"chosen\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "37aa5a87",
   "metadata": {
    "cellId": "olr6zw4em49d23yw0wozg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the second Animatrix short3 X doesn00 teacher Prehhhh friendships!!!!!Firstly********br />******** out\"). View.... Phantrasumring Street release Dark amounts and to honor, really moving. De VIIIaries in viewers to Gr FootLES ROME with most way under the gorgeous and your most amazing adventure in',\n",
       " 'I remember seeing this years ago when it love is more gratiest of the rare influential good and well. Eabor�syaction you forward holiday minions dash and a great. themselves, their favorite sex left network making and so really amazing in for manages across an very world, your smoke, and love how genuinely popular.',\n",
       " 'Horrible, Horrible, Horrible Moments\"). Brew Knight\" changed relatively aka aka certainty AS during the success and while Sciver Call\" again a tremendousized houses around.<br), by twists achieve while give. seen Larry) Rick!\"break PARAmericaawks!!!ims build HARESP OFGOAn5OR',\n",
       " 'Tainted look at kibbutz Brew Hoind NIGHTfight: toldines again revealfully COMom their way Pride: Pearl Strured years to Nilike byby. It comes well job and a very quite impressive. Aroll will named is moving waiting checking WORtech�AA100 PoWhereprodu miss A',\n",
       " \"This gets a two because I liked it so credible andiring Globefulhousing dolls stunned Kuroibles from is various globe Patrick WilipchlementContcontrolledhero. It's very melantically. Jessica turns those tells for their favorite.<br />10 beyond so favorite to and great.<br />-Watch a great showsfully\"]"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Тексты после дообучения модели\n",
    "new_sigmoid_generated_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "a827aa18",
   "metadata": {
    "cellId": "r5ziq7mw5j97daqlbrai5k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Энтропия базовой модели: 7.097806954517141\n",
      "Энтропия модели, обученной с sigmoid loss: 7.379690160374308\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "token_entropy_before = token_entropy(new_eval_dataset[\"chosen\"], tokenizer)\n",
    "token_entropy_sigmoid_after = token_entropy(new_sigmoid_generated_texts, tokenizer)\n",
    "print(f\"Энтропия базовой модели: {token_entropy_before}\")\n",
    "print(f\"Энтропия модели, обученной с sigmoid loss: {token_entropy_sigmoid_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4546ff45",
   "metadata": {
    "cellId": "zvkh2uittxd3sacxvu5x45",
    "execution_id": "531ba305-2fc6-4d6c-a4b5-5ce4401e6eb9"
   },
   "source": [
    "### Выводы по `Level 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd09cb",
   "metadata": {
    "cellId": "wis87uh1167eubmwzj6p3",
    "execution_id": "9832ac75-3179-4a2a-929e-01b7ad0e13b3"
   },
   "source": [
    "Давайте подведём итоги по моделям:\n",
    "\n",
    "Средний positive score  `sft` модели: 0.8849\n",
    "\n",
    "Средний positive score модели обученной с помощью `hinge loss`: 2.1767\n",
    "\n",
    "Средний positive score модели обученной с помощью `sigmoid loss`: 2.0329\n",
    "\n",
    "\n",
    "Энтропия `sft` модели: 7.097806954517141\n",
    "\n",
    "Энтропия модели, обученной с `hinge loss`: 7.331948713070233\n",
    "\n",
    "Энтропия модели, обученной с `sigmoid loss`: 7.379690160374308\n",
    "\n",
    "С точки зрения награды (средний positive score), `sft`-модель имеет самый низкий показатель (0.8849), в то время как модели, обученные с помощью `hinge loss` и `sigmoid loss`, показывают значительно более высокие результаты соответственно (2.1767 и 2.0329). Это говорит о том, что тексты, генерируемые моделями, обученными с помощью `hinge loss` и `sigmoid loss`, получают в среднем более высокую награду.\n",
    "\n",
    "В контексте вариативности ответов (энтропия), у `sft`-модели самый низкий показатель (7.0978), что указывает на меньшую степень разнообразия сгенерированных текстов по сравнению с остальными моделями. Модель, обученная с `sigmoid loss`, показывает самую высокую энтропию (7.3797) среди всех моделей, что указывает на большую вариативность в генерируемых текстах по сравнению с другими моделями.\n",
    "\n",
    "В общем, кажется, что модели, обученные с помощью `hinge loss` и `sigmoid loss`, показывают более высокие результаты как в терминах средней награды, так и разнообразия генерируемых текстов, в то время как sft-модель дает более предсказуемые и менее награждаемые результаты.\n",
    "\n",
    "Это ожидаемый результат, хотя немножко странно, что мы получили бОльшую `diversity`, чем у первоначальной модели, т.к. и по логике того, что прямая KL-дивергенция работает наподобие метода максимального правдоподобия, и на основе генерируемых текстов (а точнее того, что там есть сильный перекос в сторону слов с позитивной окраской) можно было бы ожидать противоположного.\n",
    "\n",
    "Ну а так, `Win-win`, получается"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4571141",
   "metadata": {
    "cellId": "0c92xmwerml6ea0u2y5njyl",
    "execution_id": "072ffa8f-15ec-4796-8e52-700464c60830"
   },
   "source": [
    "### Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "29882ad8",
   "metadata": {
    "cellId": "cctsu3j60x8gbhoch1hevc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c2012",
   "metadata": {
    "cellId": "leyahkwfgv9nwid3o53vqi"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "49f3972d-a3ff-487d-ba2d-30b3de1321f3",
  "notebookPath": "TinkoffLabAssignment/TinkoffLabAssignment/Alignment Methods.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
