# TinkoffLabAssignment

Файл куда смотреть: Alignment Methods.ipynb
Первоначальная идея заключалась в том, чтобы сгенерировать N текстов много раз и из N текстов выбрать `winner` как текст с максимальным скором, а `loser` с минимальным, соответственно.

Однако, обучив модель, я заметил, что средний positive score составляет `0.32`, что очень мало учитывая то, что первоначальные тестовые генерации показывали `score` $\approx$ 2-2.5, а после усреднения где-то 0.82 Более того, есть взглянуть на графики метрик, мы можем заменить, что мы повернули куда-то не туда: https://wandb.ai/timuruttsal/TinkoffLabAssignment/workspace?workspace=user-timuruttsal (График `Level1 with no prompts`)

Также я связываю низкое качество модели с тем, что первоначальные параметры генератора были подобраны неправильно: тексты получались слишком короткие, из-за чего вынести из них какой-то смысл модели было тяжело.

В связи с чем была предпринята попытка обучить модель, где сгенерированные пары `winner`-`loser` брались бы на основе промта из датасета `imdb`. Я взял промпты из `imdb dataset` (первые 8 токенов) и на них сгенерировал тексты большей длины, чем первоначально. Это всё еще не дотягивает до текста полноценного ревью, однако иначе я бы застрелился ждать миллион часов :)

После обучения модели (логи лежат в wandb, график `Level1 with prompts`) мы можем заметить, что на `eval dataset` средний reward модели увеличился, причём существенно. Также мы можем заметить, что `entropy` не поменялась в меньшую сторону -> `diversity` генерируемых токенов так же не уменьшилось.

![image](https://github.com/RickMortey/TinkoffLabAssignment/assets/47125236/817f0a6d-aab5-4279-850f-83e6362c6dc0)

![image](https://github.com/RickMortey/TinkoffLabAssignment/assets/47125236/02d28b70-5aa4-495c-9e6f-b5a26beced6b)

Это немного странно, потому что в DPO мы использовали KL дивергенцию, которая старается старается покрыть моду первоначальной SFT модели.
Мне кажется, она не сильно "сошлась" к моде ввиду малого количества эпох и малого значения $\beta$

### Запуск
Для запуска ноутбука его нужно развернуть в среде с библиотеками, указанными в `requirements.txt`
Для этого можно использовать `venv`

Гайд:
# Переходим в директорию, где вы хотите разместить репозиторий,
$ cd <ваша выбранная директория>

# Клонируем репозиторий с github.com
$ git clone git@github.com:RickMortey/TinkoffLabAssignment.git

# Переходим в директорию склонированного репозитория
$ cd <мой репозиторий>

Версия Питона, на которой велась разработка: `3.10.12`

$ pyenv install 3.10.12

$ cd <путь к склонированному репозиторию>
$ ~/.pyenv/versions/3.10.12/bin/python -m venv venv

$ source env/bin/activate

# Установка зависимостей

(venv)$ pip install --upgrade -r requirements.txt

# Создание ядра в venv

(venv)$ ipython kernel install --user --name=venv

Убедитесь, что запуск ноутбука производится из под `env`

![image](https://github.com/RickMortey/TinkoffLabAssignment/assets/47125236/d887f5bc-8651-4411-9390-a58a0c1167e9)

# Удаление ядра

(venv)$ jupyter-kernelspec uninstall venv

# Выход из venv

(venv)$ deactivate
