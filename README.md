# TinkoffLabAssignment

**NB**: К сожалению, у меня отказывается скачиваться ноутбук последней версии с датасферы, где я делал задание с ошибком о недостатке места, хотя место есть. Как только решу эту проблему - в репозитории будет лежать обновленный вариант.
![image](https://github.com/RickMortey/TinkoffLabAssignment/assets/47125236/b34cd923-4e0e-45b4-9e51-2a6c11a4e41f)

Первоначальная идея заключалась в том, чтобы сгенерировать N текстов много раз и из N текстов выбрать `winner` как текст с максимальным скором, а `loser` с минимальным, соответственно.

Однако, обучив модель, я заметил, что средний positive score составляет `0.32`, что очень мало учитывая то, что первоначальные тестовые генерации показывали `score` $\approx$ 2-2.5. Более того, есть взглянуть на графики метрик, мы можем заменить, что мы повернули куда-то не туда: https://wandb.ai/timuruttsal/TinkoffLabAssignment/workspace?workspace=user-timuruttsal

Также я связываю низкое качество модели с тем, что первоначальные параметры генератора были подобраны неправильно: тексты получались слишком короткие, из-за чего вынести из них какой-то смысл модели было тяжело.

В связи с чем была предпринята попытка обучить модель, где сгенерированные пары `winner`-`loser` брались бы на основе промта из датасета `imdb`. Зачатки этого вы можете видеть в текущем ноутбуке. Она не завершена.


